\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{indentfirst}

\title{EE451 Final Project Proposal: \\Predicting Optimal Thread Count in Kernel Based Image Processing}

\author{Nathan Frank, Alex Baker, Grace Susanto}
\date{March 2021}

\begin{document}

\maketitle

\section{Introduction}

As the resolution of images increases with camera and display technology advances, there is a need for faster methods of doing basic kernel based operations to images such as Edge detection, sharpening, and blurring.  This problem is meaningful because as time goes on image sizes will only continue to increase.  In order to quickly compute operations the employ of multiple workers whether they be threads in a CPU or nodes in a network will be necessary to keep the the processing time to an acceptable level.  However, the brute force approach will often overshoot what is required for optimal speedup.  As higher thread count processors become more commonplace as well, the fastest calculation might not be with the largest amount of threads due to the accumulation of overhead on thread creation and exit.

The problem being addressed by this project is the optimization of a generalized kernel based image processor by training a program on what thread counts are optimal for the machine it is running on so the program can preemptively choose an optimal thread count before the calculation, thereby avoiding unnecessary overhead.

\section{Background}

In one of the most popular open source raster-based image editing programs, GIMP (GNU Image Manipulation Program) support for applying these techniques to images using multiple threads is still not fully integrated.  But, the parts that are do support multi-threading are only ever run at the user-defined thread count.  As the average image size increases this problem will become more pronounced and the need for more intelligent image processing will similarly arise.  The purpose of this project is to determine if training a program to avoid overhead will provide any meaningful increase to the performance.  There are not any consumer programs that function in a way that avoids unnecessary overhead.

\pagebreak

\section{Proposed Work}
\subsection{Focus}

The focus of this project will be the performance and how scalable the proposed techniques are.  To evaluate this we will be running each operation for varying amounts of threads and varying image sizes with a 3x3 kernel and updating the optimal thread-counts for each pixel count.  Then, after training the program, we will be running a group of test images through the program and logging what thread count the program chose for that image and what the actual optimal thread count is as well as how much time was saved or lost by the program choosing that thread count.

\subsection{Language and Platform}

This project will be done using C++ and POSIX threads (pthread).  We will be using this language as it is scalable, does not rely on the GPU, and can be compiled onto any target platform which falls in line with the goal of creating a generalized solution to the problem at hand.  If we were to use CUDA it would then require special hardware beyond a basic computer, it would require a NVIDIA GPU.

\subsection{Technical Approach}

We will break down the program into three main phases.  Those are pre-processing, training, and testing.

Pre-processing:  For this phase the program will go through all input images and tag them with their pixel counts and which group they belong to.

Training: In this phase of the program it will go through each image for all test thread counts and average the most optimal thread count into the means current most optimal thread count.  The per image per thread count execution time will also be logged in order to capture the speedup of each image for both debugging and analysis in the final report.

Testing: For the testing phase of the program, a image falling into each mean data set will be processed at the optimal thread count decided by the program and then the resulting time will be compared against that images results from the training phase.  The speedup or slowdown caused by the program's optimal thread count will be logged.

The program is planned to be done entirely in C++ using POSIX threads.  It will be broken into several files in order to better distribute the workload between group members.  The project is managed using GitHub with the any latex files being hosted on an overleaf project that is synced to the GitHub repository.

\pagebreak

\subsection{Evaluation}

The results expected are smaller thread counts to be optimal for much smaller images and larger thread counts to be optimal for very large images.  We will be using the images from the  ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2012-2017.  This is a set of 100,000 images that we will be grouping into different sizes using a k-means grouping with the standard resolutions of 480p, 720p, 1080p, 1440p, and 2160p as the starting points with total pixel count as the metric for the grouping.  The link for the data-set is http://image-net.org/download

\subsection{Challenges}

The challenges for this project are implementing the program as listed above.  Our main goal will be to address the issues with computation of kernel based image processing on large images and computing what will produce that fastest performance for each image size.  By the end of the experiment, using the data captured we should be able to predict how many threads and what kernel size to use for a given image to produce the output as fast as possible before the computation begins.

\end{document}